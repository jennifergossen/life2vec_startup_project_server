#!/usr/bin/env python3
"""
STARTUP2VEC COMPLETE INTERPRETABILITY ANALYSIS - FULL VERSION
Complete interpretability analysis with FIXED balanced sampling, CUDA memory management, 
and ALL analysis methods included
"""

import torch
import numpy as np
import pandas as pd
import pickle
import sys
import os
import time
import gc
from pathlib import Path
from sklearn.metrics import (confusion_matrix, classification_report, roc_auc_score, roc_curve,
                           balanced_accuracy_score, f1_score, precision_recall_curve,
                           precision_score, recall_score, average_precision_score)
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from sklearn.manifold import TSNE
import matplotlib.pyplot as plt
import seaborn as sns
from collections import defaultdict, Counter
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

# Add src to path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root / "src"))

class CompleteFullStartupInterpretabilityAnalyzer:
    """COMPLETE FULL interpretability analyzer with ALL analyses and CUDA memory management"""
    
    def __init__(self, checkpoint_path, pretrained_path, output_dir="startup_interpretability_full"):
        self.checkpoint_path = checkpoint_path
        self.pretrained_path = pretrained_path
        self.output_dir = output_dir
        self.model = None
        self.datamodule = None
        
        # Core data
        self.predictions = None
        self.probabilities = None
        self.labels = None
        self.embeddings = None
        self.sequences = None
        self.metadata = None
        
        # Vocabulary
        self.vocab_to_idx = None
        self.idx_to_vocab = None
        
        # Token categories and analysis
        self.token_categories = None
        self.startup_characteristics = None
        self.token_frequencies = None
        
        # Additional analysis results
        self.performance_metrics = None
        self.token_importance_scores = None
        self.embedding_analysis = None
        self.bias_analysis = None
        self.prediction_analysis = None
        
        os.makedirs(output_dir, exist_ok=True)
    
    def clear_cuda_cache(self):
        """Clear CUDA cache to free memory"""
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            gc.collect()
    
    def load_model_and_data(self):
        """Load model and data with vocabulary - FIXED CUDA handling"""
        print("üîç Loading model, data, and parsing vocabulary...")
        
        try:
            from models.survival_model import StartupSurvivalModel
            from dataloaders.survival_datamodule import SurvivalDataModule
            
            # FIXED: Load model to CPU first
            print("üì• Loading model to CPU first...")
            self.model = StartupSurvivalModel.load_from_checkpoint(
                self.checkpoint_path,
                pretrained_model_path=self.pretrained_path,
                map_location='cpu'  # CRITICAL: Always load to CPU first
            )
            self.model.eval()
            print("‚úÖ Model loaded to CPU successfully")
            
            # Load datamodule with smaller batch size to help with memory
            print("üì• Loading datamodule...")
            self.datamodule = SurvivalDataModule(
                corpus_name="startup_corpus",
                vocab_name="startup_vocab",
                batch_size=16,  # Reduced from 32 to help with memory
                num_workers=1,  # Reduced workers
                prediction_windows=[1, 2, 3, 4]
            )
            self.datamodule.setup()
            print("‚úÖ Datamodule loaded successfully")
            
            # Extract and parse vocabulary
            self._extract_vocabulary()
            
            return True
            
        except Exception as e:
            print(f"‚ùå Error loading model/data: {e}")
            return False
    
    def _extract_vocabulary(self):
        """Extract vocabulary and parse token categories from actual structure"""
        try:
            # Extract vocabulary
            if hasattr(self.datamodule, 'vocabulary'):
                self.vocab_to_idx = self.datamodule.vocabulary.token2index
                self.idx_to_vocab = self.datamodule.vocabulary.index2token
                print(f"‚úÖ Vocabulary extracted: {len(self.vocab_to_idx):,} tokens")
            else:
                print("‚ö†Ô∏è Could not extract vocabulary")
                return
            
            # Parse token categories based on actual token structure
            self.token_categories = self._parse_token_categories()
            
            print(f"\nüìã Token Categories Found:")
            for category, tokens in self.token_categories.items():
                print(f"  {category}: {len(tokens)} tokens")
                # Show examples
                examples = list(tokens.keys())[:3]
                if examples:
                    example_names = [self.idx_to_vocab.get(token, f"Token_{token}") for token in examples]
                    print(f"    Examples: {', '.join(example_names)}")
            
        except Exception as e:
            print(f"‚ö†Ô∏è Vocabulary parsing failed: {e}")
    
    def _parse_token_categories(self):
        """Parse vocabulary into categories based on actual token structure"""
        categories = {
            # Company characteristics
            'company_country': {},          
            'company_category': {},         
            'company_employee_size': {},    
            'company_industry': {},         
            'company_business_model': {},   
            'company_technology': {},       
            
            # Event types and categories
            'event_types': {},              
            'event_categories': {},         
            'event_terms': {},              
            'event_roles': {},              
            
            # People/roles
            'people_jobs': {},              
            'people_terms': {},             
            'people_job_titles': {},        
            
            # Education events
            'education_degree_type': {},    
            'education_institution': {},    
            'education_subject': {},        
            
            # Investment events
            'investment_types': {},         
            'investment_investor_types': {},
            'investment_amounts': {},       
            'investment_fund_sizes': {},    
            'investment_counts': {},        
            'investment_valuations': {},    
            'investment_other': {},         
            
            # Acquisition events
            'acquisition_types': {},        
            'acquisition_prices': {},       
            'acquisition_other': {},        
            
            # IPO events
            'ipo_exchanges': {},            
            'ipo_money_raised': {},         
            'ipo_share_prices': {},         
            'ipo_valuations': {},           
            'ipo_other': {},                
            
            # Temporal
            'days_since_founding': {},      
        }
        
        for token_str, token_id in self.vocab_to_idx.items():
            # Company characteristics
            if token_str.startswith('COUNTRY_'):
                categories['company_country'][token_id] = token_str
            elif token_str.startswith('CATEGORY_'):
                categories['company_category'][token_id] = token_str
            elif token_str.startswith('EMPLOYEE_'):
                categories['company_employee_size'][token_id] = token_str
            elif token_str.startswith('INDUSTRY_'):
                categories['company_industry'][token_id] = token_str
            elif token_str.startswith('MODEL_'):
                categories['company_business_model'][token_id] = token_str
            elif token_str.startswith('TECH_'):
                categories['company_technology'][token_id] = token_str
            
            # Events
            elif token_str.startswith('EVT_TYPE_'):
                categories['event_types'][token_id] = token_str
            elif token_str.startswith('EVT_CAT_'):
                categories['event_categories'][token_id] = token_str
            elif token_str.startswith('EVT_TERM_'):
                categories['event_terms'][token_id] = token_str
            elif token_str.startswith('EVENT_ROLES_'):
                categories['event_roles'][token_id] = token_str
            
            # People
            elif token_str.startswith('PPL_JOB_'):
                categories['people_jobs'][token_id] = token_str
            elif token_str.startswith('PPL_TERM_'):
                categories['people_terms'][token_id] = token_str
            elif token_str.startswith('PEOPLE_JOB_TITLE_'):
                categories['people_job_titles'][token_id] = token_str
            
            # Education
            elif token_str.startswith('EDU_DEGREE_TYPE_'):
                categories['education_degree_type'][token_id] = token_str
            elif token_str.startswith('EDU_INSTITUTION_'):
                categories['education_institution'][token_id] = token_str
            elif token_str.startswith('EDU_SUBJECT_'):
                categories['education_subject'][token_id] = token_str
            
            # Investment
            elif token_str.startswith('INV_INVESTMENT_TYPE_'):
                categories['investment_types'][token_id] = token_str
            elif token_str.startswith('INV_INVESTOR_TYPES_'):
                categories['investment_investor_types'][token_id] = token_str
            elif token_str.startswith('INV_RAISED_AMOUNT_USD_'):
                categories['investment_amounts'][token_id] = token_str
            elif token_str.startswith('INV_FUND_SIZE_USD_'):
                categories['investment_fund_sizes'][token_id] = token_str
            elif token_str.startswith('INV_INVESTOR_COUNT_'):
                categories['investment_counts'][token_id] = token_str
            elif token_str.startswith('INV_POST_MONEY_VALUATION_USD_'):
                categories['investment_valuations'][token_id] = token_str
            elif token_str.startswith('INV_'):
                categories['investment_other'][token_id] = token_str
            
            # Acquisition
            elif token_str.startswith('ACQ_ACQUISITION_TYPE_'):
                categories['acquisition_types'][token_id] = token_str
            elif token_str.startswith('ACQ_PRICE_USD_'):
                categories['acquisition_prices'][token_id] = token_str
            elif token_str.startswith('ACQ_'):
                categories['acquisition_other'][token_id] = token_str
            
            # IPO
            elif token_str.startswith('IPO_EXCHANGE_'):
                categories['ipo_exchanges'][token_id] = token_str
            elif token_str.startswith('IPO_MONEY_RAISED_USD_'):
                categories['ipo_money_raised'][token_id] = token_str
            elif token_str.startswith('IPO_SHARE_PRICE_USD_'):
                categories['ipo_share_prices'][token_id] = token_str
            elif token_str.startswith('IPO_VALUATION_USD_'):
                categories['ipo_valuations'][token_id] = token_str
            elif token_str.startswith('IPO_'):
                categories['ipo_other'][token_id] = token_str
            
            # Temporal
            elif token_str.startswith('DAYS_'):
                categories['days_since_founding'][token_id] = token_str
        
        return categories
    
    def calculate_matthews_correlation_coefficient(self):
        """Calculate MCC (Matthews Correlation Coefficient) like in finetuning"""
        try:
            from sklearn.metrics import matthews_corrcoef
            mcc = matthews_corrcoef(self.labels, self.predictions)
            return mcc
        except Exception as e:
            print(f"‚ö†Ô∏è Could not calculate MCC: {e}")
            return float('nan')
    
    def extract_data_with_characteristics(self, target_batches=500, balanced_sampling=False):
        """Extract data with FIXED balanced sampling option and CUDA memory management"""
        print(f"\nüéØ EXTRACTING DATA WITH TOKEN ANALYSIS")
        print("="*60)
        
        if balanced_sampling:
            print("üéØ Using FIXED balanced sampling strategy...")
            return self._extract_balanced_data_FIXED(target_batches)
        else:
            print("üìä Using original data distribution...")
            return self._extract_standard_data_FIXED(target_batches)
    
    def _extract_standard_data_FIXED(self, target_batches):
        """Standard data extraction with FIXED CUDA memory management"""
        val_loader = self.datamodule.val_dataloader()
        max_batches = min(target_batches, len(val_loader)) if target_batches > 0 else len(val_loader)
        
        all_predictions = []
        all_probabilities = []
        all_labels = []
        all_embeddings = []
        all_sequences = []
        all_metadata = []
        
        # FIXED: Better device handling with fallback
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
        
        print(f"üîç Attempting to use device: {device}")
        
        # CRITICAL FIX: Try GPU first, fallback to CPU if OOM
        try:
            # Clear any existing GPU memory first
            if torch.cuda.is_available():
                self.clear_cuda_cache()
            
            self.model = self.model.to(device)
            print(f"‚úÖ Model successfully loaded to {device}")
            
            # Check available memory after model loading
            if device == 'cuda':
                allocated = torch.cuda.memory_allocated() / 1024**3
                print(f"üìä GPU memory after model load: {allocated:.2f}GB")
                
        except RuntimeError as e:
            if "out of memory" in str(e).lower():
                print(f"‚ö†Ô∏è CUDA out of memory during model loading!")
                print(f"üí° Falling back to CPU inference...")
                
                # Clear cache and try CPU
                self.clear_cuda_cache()
                
                device = 'cpu'
                self.model = self.model.to(device)
                print(f"‚úÖ Model loaded to CPU successfully")
            else:
                raise e
        
        print(f"Processing {max_batches:,} batches on {device}...")
        
        successful_batches = 0
        
        with torch.no_grad():
            for batch_idx, batch in enumerate(val_loader):
                if target_batches > 0 and batch_idx >= max_batches:
                    break
                
                if batch_idx % 50 == 0:
                    print(f"  Batch {batch_idx}/{max_batches} (successful: {successful_batches})", end='\r')
                    
                    # Clear cache periodically if using GPU
                    if device == 'cuda' and batch_idx % 100 == 0:
                        self.clear_cuda_cache()
                
                try:
                    input_ids = batch['input_ids'].to(device)
                    padding_mask = batch['padding_mask'].to(device)
                    survival_labels = batch['survival_label'].to(device)
                    
                    # Forward pass
                    outputs = self.model.forward(
                        input_ids=input_ids,
                        padding_mask=padding_mask
                    )
                    
                    survival_logits = outputs['survival_logits']
                    survival_probs = torch.softmax(survival_logits, dim=1)[:, 1]
                    survival_preds = torch.argmax(survival_logits, dim=1)
                    
                    transformer_output = outputs['transformer_output']
                    company_embeddings = transformer_output[:, 0, :]
                    
                    # Move to CPU immediately to save GPU memory
                    all_predictions.extend(survival_preds.cpu().numpy())
                    all_probabilities.extend(survival_probs.cpu().numpy())
                    all_labels.extend(survival_labels.squeeze().cpu().numpy())
                    all_embeddings.extend(company_embeddings.cpu().numpy())
                    all_sequences.extend(input_ids[:, 0, :].cpu().numpy())
                    
                    # Extract metadata
                    for i in range(input_ids.size(0)):
                        metadata = self._extract_metadata(batch, i, input_ids[i, 0, :])
                        all_metadata.append(metadata)
                    
                    successful_batches += 1
                    
                    # Clear GPU tensors immediately
                    del input_ids, padding_mask, survival_labels, outputs
                    del survival_logits, survival_probs, survival_preds, transformer_output, company_embeddings
                    
                except RuntimeError as e:
                    if "out of memory" in str(e).lower():
                        print(f"\n‚ö†Ô∏è CUDA OOM at batch {batch_idx}, clearing cache and continuing...")
                        self.clear_cuda_cache()
                        continue
                    else:
                        print(f"\nError in batch {batch_idx}: {e}")
                        continue
                except Exception as e:
                    print(f"\nUnexpected error in batch {batch_idx}: {e}")
                    continue
        
        print(f"\n‚úÖ Data extraction complete: {len(all_predictions):,} samples from {successful_batches} successful batches")
        
        if len(all_predictions) == 0:
            print("‚ùå No data extracted! Model may be too large for available memory.")
            return False
        
        # Store results
        self.predictions = np.array(all_predictions)
        self.probabilities = np.array(all_probabilities)
        self.labels = np.array(all_labels)
        self.embeddings = np.array(all_embeddings)
        self.sequences = all_sequences
        self.metadata = all_metadata
        
        # Additional analyses
        self._parse_startup_characteristics()
        self._analyze_token_frequency()
        self._detailed_performance_analysis()
        
        return True
    
    def _extract_balanced_data_FIXED(self, target_batches):
        """FIXED: Extract truly balanced data with proper CUDA memory management"""
        val_loader = self.datamodule.val_dataloader()
        
        # FIXED: Separate collections for truly different samples
        survival_data = {
            'predictions': [],
            'probabilities': [],
            'labels': [],
            'embeddings': [],
            'sequences': [],
            'metadata': []
        }
        
        failure_data = {
            'predictions': [],
            'probabilities': [],
            'labels': [],
            'embeddings': [],
            'sequences': [],
            'metadata': []
        }
        
        target_per_class = target_batches * 8  # Adjusted for batch size 16
        
        # FIXED: Better device handling with fallback
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
        
        print(f"üîç Attempting to use device: {device}")
        
        # CRITICAL FIX: Try GPU first, fallback to CPU if OOM
        try:
            if torch.cuda.is_available():
                self.clear_cuda_cache()
            
            self.model = self.model.to(device)
            print(f"‚úÖ Model successfully loaded to {device}")
            
            if device == 'cuda':
                allocated = torch.cuda.memory_allocated() / 1024**3
                print(f"üìä GPU memory after model load: {allocated:.2f}GB")
                
        except RuntimeError as e:
            if "out of memory" in str(e).lower():
                print(f"‚ö†Ô∏è CUDA out of memory during model loading!")
                print(f"üí° Falling back to CPU inference...")
                
                self.clear_cuda_cache()
                device = 'cpu'
                self.model = self.model.to(device)
                print(f"‚úÖ Model loaded to CPU successfully")
            else:
                raise e
        
        print(f"Collecting FIXED balanced samples (target: {target_per_class} per class)...")
        
        with torch.no_grad():
            for batch_idx, batch in enumerate(val_loader):
                # Stop when we have enough of both classes
                if (len(survival_data['labels']) >= target_per_class and 
                    len(failure_data['labels']) >= target_per_class):
                    break
                
                if batch_idx % 50 == 0:
                    survived = len(survival_data['labels'])
                    failed = len(failure_data['labels'])
                    print(f"  Batch {batch_idx}: {survived} survived, {failed} failed", end='\r')
                    
                    # Clear cache periodically
                    if device == 'cuda' and batch_idx % 100 == 0:
                        self.clear_cuda_cache()
                
                try:
                    input_ids = batch['input_ids'].to(device)
                    padding_mask = batch['padding_mask'].to(device)
                    survival_labels = batch['survival_label'].to(device)
                    
                    # Forward pass
                    outputs = self.model.forward(
                        input_ids=input_ids,
                        padding_mask=padding_mask
                    )
                    
                    survival_logits = outputs['survival_logits']
                    survival_probs = torch.softmax(survival_logits, dim=1)[:, 1]
                    survival_preds = torch.argmax(survival_logits, dim=1)
                    
                    transformer_output = outputs['transformer_output']
                    company_embeddings = transformer_output[:, 0, :]
                    
                    # FIXED: Separate by TRUE LABELS into different data structures
                    for i in range(input_ids.size(0)):
                        true_label = survival_labels[i].squeeze().item()
                        
                        sample_data = {
                            'prediction': survival_preds[i].cpu().numpy(),
                            'probability': survival_probs[i].cpu().numpy(),
                            'label': true_label,
                            'embedding': company_embeddings[i].cpu().numpy(),
                            'sequence': input_ids[i, 0, :].cpu().numpy(),
                            'metadata': self._extract_metadata(batch, i, input_ids[i, 0, :])
                        }
                        
                        # CRITICAL FIX: Store in separate collections based on TRUE LABEL
                        if true_label == 1 and len(survival_data['labels']) < target_per_class:
                            # This is a SURVIVED startup
                            survival_data['predictions'].append(sample_data['prediction'])
                            survival_data['probabilities'].append(sample_data['probability'])
                            survival_data['labels'].append(sample_data['label'])
                            survival_data['embeddings'].append(sample_data['embedding'])
                            survival_data['sequences'].append(sample_data['sequence'])
                            survival_data['metadata'].append(sample_data['metadata'])
                            
                        elif true_label == 0 and len(failure_data['labels']) < target_per_class:
                            # This is a FAILED startup
                            failure_data['predictions'].append(sample_data['prediction'])
                            failure_data['probabilities'].append(sample_data['probability'])
                            failure_data['labels'].append(sample_data['label'])
                            failure_data['embeddings'].append(sample_data['embedding'])
                            failure_data['sequences'].append(sample_data['sequence'])
                            failure_data['metadata'].append(sample_data['metadata'])
                    
                    # Clear GPU tensors immediately
                    del input_ids, padding_mask, survival_labels, outputs
                    del survival_logits, survival_probs, survival_preds, transformer_output, company_embeddings
                    
                except RuntimeError as e:
                    if "out of memory" in str(e).lower():
                        print(f"\n‚ö†Ô∏è CUDA OOM at batch {batch_idx}, clearing cache and continuing...")
                        self.clear_cuda_cache()
                        continue
                    else:
                        print(f"\nError in batch {batch_idx}: {e}")
                        continue
                except Exception as e:
                    print(f"\nUnexpected error in batch {batch_idx}: {e}")
                    continue
        
        # FIXED: Combine truly different samples
        min_samples = min(len(survival_data['labels']), len(failure_data['labels']))
        
        print(f"\n‚úÖ FIXED balanced sampling complete!")
        print(f"   ÔøΩÔøΩ Collected: {len(survival_data['labels'])} survived, {len(failure_data['labels'])} failed")
        print(f"   ‚öñÔ∏è Using: {min_samples} per class ({min_samples * 2} total)")
        
        if min_samples == 0:
            print("‚ùå No balanced samples collected! Try increasing target_batches or checking data.")
            return False
        
        # Combine the balanced data
        self.predictions = np.concatenate([
            np.array(survival_data['predictions'][:min_samples]),
            np.array(failure_data['predictions'][:min_samples])
        ])
        
        self.probabilities = np.concatenate([
            np.array(survival_data['probabilities'][:min_samples]),
            np.array(failure_data['probabilities'][:min_samples])
        ])
        
        self.labels = np.concatenate([
            np.array(survival_data['labels'][:min_samples]),
            np.array(failure_data['labels'][:min_samples])
        ])
        
        self.embeddings = np.vstack([
            np.array(survival_data['embeddings'][:min_samples]),
            np.array(failure_data['embeddings'][:min_samples])
        ])
        
        self.sequences = (survival_data['sequences'][:min_samples] + 
                         failure_data['sequences'][:min_samples])
        
        self.metadata = (survival_data['metadata'][:min_samples] + 
                        failure_data['metadata'][:min_samples])
        
        # Verify the fix worked
        unique_labels, counts = np.unique(self.labels, return_counts=True)
        print(f"   ‚úÖ Final distribution: {dict(zip(unique_labels, counts))}")
        
        # Additional analyses
        self._parse_startup_characteristics()
        self._analyze_token_frequency()
        self._detailed_performance_analysis()
        
        return True
    
    def _extract_metadata(self, batch, sample_idx, sequence):
        """Extract metadata including characteristics parsed from tokens"""
        try:
            base_metadata = {
                'batch_idx': batch['sequence_id'][sample_idx].item() if 'sequence_id' in batch else -1,
                'sample_idx': sample_idx,
                'sequence_length': (sequence > 0).sum().item(),
                'prediction_window': batch['prediction_window'][sample_idx].item() if 'prediction_window' in batch else 1,
                'company_age': batch['company_age_at_prediction'][sample_idx].item() if 'company_age_at_prediction' in batch else 2,
                'founded_year': batch['company_founded_year'][sample_idx].item() if 'company_founded_year' in batch else 2020,
            }
            
            # Parse characteristics from tokens in sequence
            if self.token_categories:
                characteristics = self._parse_sequence_characteristics(sequence)
                base_metadata.update(characteristics)
            
            return base_metadata
        except Exception as e:
            # Return safe defaults if extraction fails
            return {
                'batch_idx': -1, 'sample_idx': sample_idx, 'sequence_length': 0,
                'prediction_window': 1, 'company_age': 2, 'founded_year': 2020,
                'country': 'Unknown', 'industry_category': 'Unknown', 'employee_size': 'Unknown',
                'business_model': 'Unknown', 'technology_type': 'Unknown',
                'has_investment_events': False, 'has_acquisition_events': False,
                'has_ipo_events': False, 'has_education_events': False, 'has_people_events': False,
                'investment_event_count': 0, 'people_job_count': 0, 'education_event_count': 0,
                'unique_token_count': 0, 'token_diversity': 0.0
            }
    
    def _parse_sequence_characteristics(self, sequence):
        """Parse sequence to extract startup characteristics from actual tokens"""
        characteristics = {
            'country': 'Unknown', 'industry_category': 'Unknown', 'employee_size': 'Unknown',
            'business_model': 'Unknown', 'technology_type': 'Unknown',
            'has_investment_events': False, 'has_acquisition_events': False,
            'has_ipo_events': False, 'has_education_events': False, 'has_people_events': False,
            'investment_event_count': 0, 'people_job_count': 0, 'education_event_count': 0,
            'unique_token_count': 0, 'token_diversity': 0.0
        }
        
        try:
            clean_sequence = sequence[sequence > 0].cpu().numpy() if torch.is_tensor(sequence) else sequence[sequence > 0]
            characteristics['unique_token_count'] = len(set(clean_sequence))
            characteristics['token_diversity'] = len(set(clean_sequence)) / len(clean_sequence) if len(clean_sequence) > 0 else 0
            
            for token_id in clean_sequence:
                token_str = self.idx_to_vocab.get(int(token_id), "")
                
                # Parse company characteristics from tokens
                if token_str.startswith('COUNTRY_'):
                    characteristics['country'] = token_str.replace('COUNTRY_', '')
                elif token_str.startswith('CATEGORY_') or token_str.startswith('INDUSTRY_'):
                    characteristics['industry_category'] = token_str.split('_', 1)[1] if '_' in token_str else 'Unknown'
                elif token_str.startswith('EMPLOYEE_'):
                    characteristics['employee_size'] = token_str.replace('EMPLOYEE_', '')
                elif token_str.startswith('MODEL_'):
                    characteristics['business_model'] = token_str.replace('MODEL_', '')
                elif token_str.startswith('TECH_'):
                    characteristics['technology_type'] = token_str.replace('TECH_', '')
                
                # Check for event presence using token categories
                if int(token_id) in self.token_categories['investment_types'] or int(token_id) in self.token_categories['investment_amounts']:
                    characteristics['has_investment_events'] = True
                    characteristics['investment_event_count'] += 1
                elif int(token_id) in self.token_categories['acquisition_types']:
                    characteristics['has_acquisition_events'] = True
                elif int(token_id) in self.token_categories['ipo_exchanges'] or int(token_id) in self.token_categories['ipo_money_raised']:
                    characteristics['has_ipo_events'] = True
                elif (int(token_id) in self.token_categories['education_degree_type'] or 
                      int(token_id) in self.token_categories['education_institution'] or 
                      int(token_id) in self.token_categories['education_subject']):
                    characteristics['has_education_events'] = True
                    characteristics['education_event_count'] += 1
                elif int(token_id) in self.token_categories['people_jobs'] or int(token_id) in self.token_categories['people_job_titles']:
                    characteristics['has_people_events'] = True
                    characteristics['people_job_count'] += 1
        except Exception as e:
            print(f"Warning: Could not parse sequence characteristics: {e}")
        
        return characteristics
    
    def _parse_startup_characteristics(self):
        """Parse all startup characteristics from token metadata"""
        print("\nüìã Parsing startup characteristics from tokens...")
        
        if not self.metadata:
            print("‚ö†Ô∏è No metadata available")
            return
        
        # Count characteristics from tokens
        countries = Counter([m['country'] for m in self.metadata])
        industries = Counter([m['industry_category'] for m in self.metadata])
        employee_sizes = Counter([m['employee_size'] for m in self.metadata])
        business_models = Counter([m['business_model'] for m in self.metadata])
        tech_types = Counter([m['technology_type'] for m in self.metadata])
        
        # Age and temporal analysis with safety checks
        ages = [m['company_age'] for m in self.metadata if m['company_age'] is not None and not np.isnan(m['company_age'])]
        years = [m['founded_year'] for m in self.metadata if m['founded_year'] is not None and not np.isnan(m['founded_year'])]
        
        print(f"\nüìä Startup Characteristics Found:")
        print(f"  Countries: {dict(countries.most_common(10))}")
        print(f"  Industries: {dict(industries.most_common(10))}")
        print(f"  Employee Sizes: {dict(employee_sizes)}")
        print(f"  Business Models: {dict(business_models)}")
        print(f"  Technology Types: {dict(tech_types.most_common(5))}")
        
        # Temporal analysis with safety checks
        if ages:
            print(f"\n‚è∞ Temporal Characteristics:")
            print(f"  Average company age: {np.mean(ages):.1f} years")
            print(f"  Age range: {np.min(ages):.1f} - {np.max(ages):.1f} years")
        
        if years:
            print(f"  Founded year range: {int(np.min(years))} - {int(np.max(years))}")
        
        # Age-based survival analysis
        if ages and len(ages) > 10:
            try:
                age_groups = pd.cut(ages, bins=5, labels=['Very Young', 'Young', 'Medium', 'Mature', 'Old'])
                print(f"\nüìà Survival by Age Group:")
                for group in age_groups.categories:
                    mask = age_groups == group
                    if mask.sum() > 10:
                        survival_rate = self.labels[mask].mean()
                        print(f"  {group}: {survival_rate:.2%} survival rate ({mask.sum()} companies)")
            except Exception as e:
                print(f"‚ö†Ô∏è Could not create age groups: {e}")
        
        # Event presence statistics
        investment_events = sum(1 for m in self.metadata if m['has_investment_events'])
        acquisition_events = sum(1 for m in self.metadata if m['has_acquisition_events'])
        ipo_events = sum(1 for m in self.metadata if m['has_ipo_events'])
        education_events = sum(1 for m in self.metadata if m['has_education_events'])
        
        print(f"\nüìà Event Presence:")
        print(f"  Investment Events: {investment_events:,} ({investment_events/len(self.metadata)*100:.1f}%)")
        print(f"  Acquisition Events: {acquisition_events:,} ({acquisition_events/len(self.metadata)*100:.1f}%)")
        print(f"  IPO Events: {ipo_events:,} ({ipo_events/len(self.metadata)*100:.1f}%)")
        print(f"  Education Events: {education_events:,} ({education_events/len(self.metadata)*100:.1f}%)")
        
        self.startup_characteristics = {
            'countries': countries, 'industries': industries, 'employee_sizes': employee_sizes,
            'business_models': business_models, 'tech_types': tech_types,
            'temporal': {'ages': ages, 'years': years},
            'event_stats': {
                'investment_events': investment_events, 'acquisition_events': acquisition_events,
                'ipo_events': ipo_events, 'education_events': education_events
            }
        }
    
    def _analyze_token_frequency(self):
        """Analyze token frequency patterns"""
        print("\nüîç TOKEN FREQUENCY ANALYSIS")
        print("-" * 40)
        
        if not self.sequences:
            print("‚ö†Ô∏è No sequences available")
            return
        
        token_counts = Counter()
        total_sequences = len(self.sequences)
        
        for sequence in self.sequences:
            clean_sequence = sequence[sequence > 0]
            for token in clean_sequence:
                token_counts[int(token)] += 1
        
        total_tokens = sum(token_counts.values())
        
        if total_tokens == 0:
            print("‚ö†Ô∏è No tokens found")
            return
        
        # High frequency tokens (>1%)
        frequent_tokens = {token: count for token, count in token_counts.items() 
                         if count/total_tokens > 0.01}
        
        # Rare tokens (<0.01%)
        rare_tokens = {token: count for token, count in token_counts.items() 
                      if count/total_tokens < 0.0001}
        
        print(f"üìä Token Frequency Statistics:")
        print(f"  Total unique tokens: {len(token_counts):,}")
        print(f"  High-frequency tokens (>1%): {len(frequent_tokens):,}")
        print(f"  Rare tokens (<0.01%): {len(rare_tokens):,}")
        print(f"  Average tokens per sequence: {total_tokens/total_sequences:.1f}")
        
        # Show top frequent tokens
        print(f"\nüî• Most Frequent Tokens:")
        for token, count in token_counts.most_common(10):
            token_name = self.idx_to_vocab.get(token, f"Token_{token}")
            freq = count/total_tokens
            print(f"  {token_name}: {count:,} ({freq:.2%})")
        
        # Analyze frequency by category
        print(f"\nüìã Frequency by Token Category:")
        for category, tokens_dict in self.token_categories.items():
            if tokens_dict:
                category_counts = [token_counts.get(token_id, 0) for token_id in tokens_dict.keys()]
                avg_freq = np.mean(category_counts) / total_tokens if category_counts else 0
                print(f"  {category}: avg {avg_freq:.3%} frequency")
        
        self.token_frequencies = {
            'token_counts': token_counts, 'frequent_tokens': frequent_tokens,
            'rare_tokens': rare_tokens, 'total_tokens': total_tokens,
            'avg_tokens_per_sequence': total_tokens/total_sequences
        }
    
    def _detailed_performance_analysis(self):
        """Enhanced performance analysis with multiple metrics"""
        print(f"\nüìä ENHANCED PERFORMANCE ANALYSIS")
        print("-"*60)
        
        if len(self.predictions) == 0:
            print("‚ùå No predictions available for analysis")
            return
        
        # Basic metrics
        accuracy = (self.predictions == self.labels).mean()
        survival_rate = self.labels.mean()
        
        # Enhanced metrics with safety checks
        try:
            balanced_acc = balanced_accuracy_score(self.labels, self.predictions)
            f1 = f1_score(self.labels, self.predictions) if len(np.unique(self.labels)) > 1 else 0
            precision = precision_score(self.labels, self.predictions) if len(np.unique(self.labels)) > 1 else 0
            recall = recall_score(self.labels, self.predictions) if len(np.unique(self.labels)) > 1 else 0
            mcc = self.calculate_matthews_correlation_coefficient()
        except Exception as e:
            print(f"‚ö†Ô∏è Could not calculate some metrics: {e}")
            balanced_acc = f1 = precision = recall = mcc = 0
        
        # AUC and AP with safety checks
        try:
            if len(np.unique(self.labels)) > 1 and len(self.probabilities) > 0:
                auc = roc_auc_score(self.labels, self.probabilities)
                ap_score = average_precision_score(self.labels, self.probabilities)
            else:
                auc = ap_score = float('nan')
        except:
            auc = ap_score = float('nan')
        
        print(f"üìà Comprehensive Performance Metrics:")
        print(f"  Total samples: {len(self.predictions):,}")
        print(f"  Class distribution: {(1-survival_rate):.1%} failed, {survival_rate:.1%} survived")
        print()
        print(f"  Standard Accuracy: {accuracy:.4f}")
        print(f"  Balanced Accuracy: {balanced_acc:.4f} ‚≠ê")
        print(f"  F1 Score: {f1:.4f}")
        print(f"  Precision: {precision:.4f}")
        print(f"  Recall: {recall:.4f}")
        print(f"  Matthews Correlation Coefficient (MCC): {mcc:.4f} ‚≠ê")
        print()
        print(f"  AUC-ROC: {auc:.4f}")
        print(f"  Average Precision (AP): {ap_score:.4f}")
        
        # Confusion matrix
        cm = confusion_matrix(self.labels, self.predictions)
        print(f"\nüìä Confusion Matrix:")
        print("    Pred:")
        print("    F    S")
        print(f"F  {cm[0,0]:4d} {cm[0,1]:4d}")
        print(f"S  {cm[1,0]:4d} {cm[1,1]:4d}")
        
        # Interpretation
        print(f"\nüéØ Performance Interpretation:")
        if balanced_acc > 0.7:
            print(f"‚úÖ Good balanced performance (Balanced Acc > 0.7)")
        elif balanced_acc > 0.6:
            print(f"üìä Moderate balanced performance (Balanced Acc > 0.6)")
        elif balanced_acc > 0.5:
            print(f"‚ö†Ô∏è Weak but above-chance performance (Balanced Acc > 0.5)")
        else:
            print(f"‚ùå Below-chance performance")
        
        if not np.isnan(mcc):
            if mcc > 0.3:
                print(f"‚úÖ Strong correlation (MCC > 0.3)")
            elif mcc > 0.1:
                print(f"üìä Moderate correlation (MCC > 0.1)")
            elif mcc > 0:
                print(f"‚ö†Ô∏è Weak positive correlation")
            else:
                print(f"‚ùå No or negative correlation")
        
        # Store metrics for later use
        self.performance_metrics = {
            'accuracy': accuracy, 'balanced_accuracy': balanced_acc, 'f1_score': f1,
            'precision': precision, 'recall': recall, 'mcc': mcc,
            'auc_roc': auc, 'average_precision': ap_score, 'survival_rate': survival_rate,
            'confusion_matrix': cm
        }
    
    # ========================================
    # ALL ADDITIONAL ANALYSIS METHODS
    # ========================================
    
    def analyze_token_importance(self):
        """Analyze which tokens are most important for predictions"""
        print("\nüîç TOKEN IMPORTANCE ANALYSIS")
        print("-" * 50)
        
        # Calculate token importance by frequency and survival correlation
        token_survival_scores = {}
        token_failure_scores = {}
        
        # Create binary masks for success/failure
        success_mask = self.labels == 1
        failure_mask = self.labels == 0
        
        for sequence, label in zip(self.sequences, self.labels):
            clean_sequence = sequence[sequence > 0]
            for token_id in clean_sequence:
                token_id = int(token_id)
                
                if token_id not in token_survival_scores:
                    token_survival_scores[token_id] = 0
                    token_failure_scores[token_id] = 0
                
                if label == 1:
                    token_survival_scores[token_id] += 1
                else:
                    token_failure_scores[token_id] += 1
        
        # Calculate importance scores
        token_importance = {}
        for token_id in token_survival_scores.keys():
            total_occurrences = token_survival_scores[token_id] + token_failure_scores[token_id]
            if total_occurrences > 5:  # Only consider tokens that appear at least 5 times
                survival_rate = token_survival_scores[token_id] / total_occurrences
                # Importance = deviation from overall survival rate
                overall_survival_rate = self.labels.mean()
                importance = abs(survival_rate - overall_survival_rate)
                token_importance[token_id] = {
                    'importance_score': importance,
                    'survival_rate': survival_rate,
                    'total_occurrences': total_occurrences,
                    'survival_occurrences': token_survival_scores[token_id],
                    'failure_occurrences': token_failure_scores[token_id]
                }
        
        # Sort by importance
        sorted_tokens = sorted(token_importance.items(), 
                             key=lambda x: x[1]['importance_score'], 
                             reverse=True)
        
        print(f"üìä Most Important Tokens (Top 20):")
        print(f"{'Token Name':<40} {'Importance':<12} {'Survival Rate':<15} {'Occurrences':<12}")
        print("-" * 79)
        
        for token_id, scores in sorted_tokens[:20]:
            token_name = self.idx_to_vocab.get(token_id, f"Token_{token_id}")
            if len(token_name) > 37:
                token_name = token_name[:34] + "..."
            
            print(f"{token_name:<40} {scores['importance_score']:<12.4f} "
                  f"{scores['survival_rate']:<15.3f} {scores['total_occurrences']:<12}")
        
        # Analyze by category
        print(f"\nüìã Token Importance by Category:")
        category_importance = {}
        
        for category, tokens_dict in self.token_categories.items():
            if tokens_dict:
                category_scores = []
                for token_id in tokens_dict.keys():
                    if token_id in token_importance:
                        category_scores.append(token_importance[token_id]['importance_score'])
                
                if category_scores:
                    avg_importance = np.mean(category_scores)
                    max_importance = np.max(category_scores)
                    category_importance[category] = {
                        'avg_importance': avg_importance,
                        'max_importance': max_importance,
                        'token_count': len(category_scores)
                    }
                    print(f"  {category:<30} Avg: {avg_importance:.4f}, Max: {max_importance:.4f}, Count: {len(category_scores)}")
        
        self.token_importance_scores = {
            'token_scores': token_importance,
            'sorted_tokens': sorted_tokens,
            'category_importance': category_importance
        }
        
        return token_importance
    
    def analyze_embeddings(self):
        """Analyze embedding patterns and clustering"""
        print("\nüß† EMBEDDING ANALYSIS")
        print("-" * 40)
        
        if self.embeddings is None or len(self.embeddings) == 0:
            print("‚ö†Ô∏è No embeddings available")
            return
        
        print(f"üìä Embedding Statistics:")
        print(f"  Shape: {self.embeddings.shape}")
        print(f"  Mean: {np.mean(self.embeddings):.4f}")
        print(f"  Std: {np.std(self.embeddings):.4f}")
        print(f"  Min: {np.min(self.embeddings):.4f}")
        print(f"  Max: {np.max(self.embeddings):.4f}")
        
        # PCA Analysis
        print(f"\nüîç PCA Analysis:")
        pca = PCA(n_components=min(10, self.embeddings.shape[1]))
        pca_embeddings = pca.fit_transform(self.embeddings)
        
        explained_variance = pca.explained_variance_ratio_
        cumulative_variance = np.cumsum(explained_variance)
        
        print(f"  Explained variance by component:")
        for i, (var, cum_var) in enumerate(zip(explained_variance[:5], cumulative_variance[:5])):
            print(f"    PC{i+1}: {var:.3f} (cumulative: {cum_var:.3f})")
        
        # Clustering Analysis
        print(f"\nüîó Clustering Analysis:")
        optimal_k = min(8, len(np.unique(self.labels)) * 4)  # Reasonable number of clusters
        
        kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)
        cluster_labels = kmeans.fit_predict(self.embeddings)
        
        print(f"  Number of clusters: {optimal_k}")
        print(f"  Cluster distribution:")
        
        cluster_survival_rates = {}
        for cluster_id in range(optimal_k):
            cluster_mask = cluster_labels == cluster_id
            cluster_size = cluster_mask.sum()
            if cluster_size > 0:
                survival_rate = self.labels[cluster_mask].mean()
                cluster_survival_rates[cluster_id] = survival_rate
                print(f"    Cluster {cluster_id}: {cluster_size} samples, {survival_rate:.3f} survival rate")
        
        # Embedding similarity analysis
        print(f"\nüìè Embedding Similarity Analysis:")
        success_embeddings = self.embeddings[self.labels == 1]
        failure_embeddings = self.embeddings[self.labels == 0]
        
        if len(success_embeddings) > 0 and len(failure_embeddings) > 0:
            success_centroid = np.mean(success_embeddings, axis=0)
            failure_centroid = np.mean(failure_embeddings, axis=0)
            
            centroid_distance = np.linalg.norm(success_centroid - failure_centroid)
            print(f"  Distance between success/failure centroids: {centroid_distance:.4f}")
            
            # Intra-class distances
            success_distances = [np.linalg.norm(emb - success_centroid) for emb in success_embeddings]
            failure_distances = [np.linalg.norm(emb - failure_centroid) for emb in failure_embeddings]
            
            print(f"  Average distance to success centroid: {np.mean(success_distances):.4f} ¬± {np.std(success_distances):.4f}")
            print(f"  Average distance to failure centroid: {np.mean(failure_distances):.4f} ¬± {np.std(failure_distances):.4f}")
        
        self.embedding_analysis = {
            'pca_embeddings': pca_embeddings,
            'explained_variance': explained_variance,
            'cluster_labels': cluster_labels,
            'cluster_survival_rates': cluster_survival_rates,
            'centroid_distance': centroid_distance if len(success_embeddings) > 0 and len(failure_embeddings) > 0 else None
        }
        
        return self.embedding_analysis
    
    def analyze_prediction_patterns(self):
        """Analyze prediction patterns and confidence"""
        print("\nüéØ PREDICTION PATTERN ANALYSIS")
        print("-" * 50)
        
        # Confidence analysis
        print(f"üìä Prediction Confidence Analysis:")
        
        # Calculate prediction confidence (distance from 0.5)
        confidences = np.abs(self.probabilities - 0.5)
        
        print(f"  Average confidence: {np.mean(confidences):.4f}")
        print(f"  Confidence std: {np.std(confidences):.4f}")
        print(f"  High confidence predictions (>0.4): {(confidences > 0.4).sum():,} ({(confidences > 0.4).mean():.1%})")
        print(f"  Low confidence predictions (<0.1): {(confidences < 0.1).sum():,} ({(confidences < 0.1).mean():.1%})")
        
        # Calibration analysis
        print(f"\nüéØ Prediction Calibration:")
        confidence_bins = np.linspace(0, 0.5, 6)
        for i in range(len(confidence_bins) - 1):
            bin_mask = (confidences >= confidence_bins[i]) & (confidences < confidence_bins[i + 1])
            if bin_mask.sum() > 10:
                bin_accuracy = (self.predictions[bin_mask] == self.labels[bin_mask]).mean()
                avg_confidence = np.mean(confidences[bin_mask])
                print(f"  Confidence {confidence_bins[i]:.2f}-{confidence_bins[i+1]:.2f}: "
                      f"{bin_mask.sum()} samples, {bin_accuracy:.3f} accuracy, {avg_confidence:.3f} avg confidence")
        
        # Error analysis
        print(f"\n‚ùå Error Analysis:")
        correct_predictions = self.predictions == self.labels
        accuracy = correct_predictions.mean()
        
        print(f"  Overall accuracy: {accuracy:.4f}")
        print(f"  Correct predictions: {correct_predictions.sum():,}")
        print(f"  Incorrect predictions: {(~correct_predictions).sum():,}")
        
        # False positive and false negative analysis
        true_positives = (self.predictions == 1) & (self.labels == 1)
        false_positives = (self.predictions == 1) & (self.labels == 0)
        true_negatives = (self.predictions == 0) & (self.labels == 0)
        false_negatives = (self.predictions == 0) & (self.labels == 1)
        
        print(f"\nüìä Prediction Breakdown:")
        print(f"  True Positives (predicted success, actual success): {true_positives.sum():,}")
        print(f"  False Positives (predicted success, actual failure): {false_positives.sum():,}")
        print(f"  True Negatives (predicted failure, actual failure): {true_negatives.sum():,}")
        print(f"  False Negatives (predicted failure, actual success): {false_negatives.sum():,}")
        
        # Confidence by prediction type
        print(f"\nüéØ Confidence by Prediction Type:")
        if true_positives.sum() > 0:
            tp_confidence = np.mean(confidences[true_positives])
            print(f"  True Positives avg confidence: {tp_confidence:.4f}")
        
        if false_positives.sum() > 0:
            fp_confidence = np.mean(confidences[false_positives])
            print(f"  False Positives avg confidence: {fp_confidence:.4f}")
        
        if true_negatives.sum() > 0:
            tn_confidence = np.mean(confidences[true_negatives])
            print(f"  True Negatives avg confidence: {tn_confidence:.4f}")
        
        if false_negatives.sum() > 0:
            fn_confidence = np.mean(confidences[false_negatives])
            print(f"  False Negatives avg confidence: {fn_confidence:.4f}")
        
        self.prediction_analysis = {
            'confidences': confidences,
            'accuracy': accuracy,
            'prediction_breakdown': {
                'true_positives': true_positives.sum(),
                'false_positives': false_positives.sum(),
                'true_negatives': true_negatives.sum(),
                'false_negatives': false_negatives.sum()
            },
            'confidence_by_type': {
                'tp_confidence': np.mean(confidences[true_positives]) if true_positives.sum() > 0 else 0,
                'fp_confidence': np.mean(confidences[false_positives]) if false_positives.sum() > 0 else 0,
                'tn_confidence': np.mean(confidences[true_negatives]) if true_negatives.sum() > 0 else 0,
                'fn_confidence': np.mean(confidences[false_negatives]) if false_negatives.sum() > 0 else 0,
            }
        }
        
        return self.prediction_analysis
    
    def analyze_algorithmic_bias(self):
        """Analyze potential algorithmic bias in predictions"""
        print("\n‚öñÔ∏è ALGORITHMIC BIAS ANALYSIS")
        print("-" * 50)
        
        if not self.metadata:
            print("‚ö†Ô∏è No metadata available for bias analysis")
            return
        
        bias_results = {}
        
        # Country bias analysis
        print(f"üåç Geographic Bias Analysis:")
        countries = [m['country'] for m in self.metadata]
        country_counter = Counter(countries)
        
        significant_countries = [country for country, count in country_counter.items() 
                               if count >= 20 and country != 'Unknown'][:10]
        
        if significant_countries:
            print(f"  Analyzing {len(significant_countries)} countries with 20+ samples")
            country_bias = {}
            
            for country in significant_countries:
                country_mask = np.array([m['country'] == country for m in self.metadata])
                if country_mask.sum() > 0:
                    country_accuracy = (self.predictions[country_mask] == self.labels[country_mask]).mean()
                    country_survival_rate = self.labels[country_mask].mean()
                    predicted_survival_rate = self.predictions[country_mask].mean()
                    
                    country_bias[country] = {
                        'sample_count': country_mask.sum(),
                        'accuracy': country_accuracy,
                        'actual_survival_rate': country_survival_rate,
                        'predicted_survival_rate': predicted_survival_rate,
                        'bias': predicted_survival_rate - country_survival_rate
                    }
                    
                    print(f"    {country}: {country_mask.sum()} samples, "
                          f"Acc: {country_accuracy:.3f}, "
                          f"Actual: {country_survival_rate:.3f}, "
                          f"Predicted: {predicted_survival_rate:.3f}, "
                          f"Bias: {country_bias[country]['bias']:+.3f}")
            
            bias_results['country_bias'] = country_bias
        
        # Industry bias analysis
        print(f"\nüè¢ Industry Bias Analysis:")
        industries = [m['industry_category'] for m in self.metadata]
        industry_counter = Counter(industries)
        
        significant_industries = [industry for industry, count in industry_counter.items() 
                                if count >= 20 and industry != 'Unknown'][:10]
        
        if significant_industries:
            print(f"  Analyzing {len(significant_industries)} industries with 20+ samples")
            industry_bias = {}
            
            for industry in significant_industries:
                industry_mask = np.array([m['industry_category'] == industry for m in self.metadata])
                if industry_mask.sum() > 0:
                    industry_accuracy = (self.predictions[industry_mask] == self.labels[industry_mask]).mean()
                    industry_survival_rate = self.labels[industry_mask].mean()
                    predicted_survival_rate = self.predictions[industry_mask].mean()
                    
                    industry_bias[industry] = {
                        'sample_count': industry_mask.sum(),
                        'accuracy': industry_accuracy,
                        'actual_survival_rate': industry_survival_rate,
                        'predicted_survival_rate': predicted_survival_rate,
                        'bias': predicted_survival_rate - industry_survival_rate
                    }
                    
                    print(f"    {industry}: {industry_mask.sum()} samples, "
                          f"Acc: {industry_accuracy:.3f}, "
                          f"Actual: {industry_survival_rate:.3f}, "
                          f"Predicted: {predicted_survival_rate:.3f}, "
                          f"Bias: {industry_bias[industry]['bias']:+.3f}")
            
            bias_results['industry_bias'] = industry_bias
        
        # Company age bias analysis
        print(f"\n‚è∞ Age Bias Analysis:")
        ages = [m['company_age'] for m in self.metadata if m['company_age'] is not None and not np.isnan(m['company_age'])]
        
        if len(ages) > 50:
            try:
                age_bins = pd.cut(ages, bins=5, labels=['Very Young', 'Young', 'Medium', 'Mature', 'Old'])
                age_bias = {}
                
                for age_group in age_bins.categories:
                    age_mask = age_bins == age_group
                    if age_mask.sum() > 10:
                        group_accuracy = (self.predictions[age_mask] == self.labels[age_mask]).mean()
                        group_survival_rate = self.labels[age_mask].mean()
                        predicted_survival_rate = self.predictions[age_mask].mean()
                        
                        age_bias[str(age_group)] = {
                            'sample_count': age_mask.sum(),
                            'accuracy': group_accuracy,
                            'actual_survival_rate': group_survival_rate,
                            'predicted_survival_rate': predicted_survival_rate,
                            'bias': predicted_survival_rate - group_survival_rate
                        }
                        
                        print(f"    {age_group}: {age_mask.sum()} samples, "
                              f"Acc: {group_accuracy:.3f}, "
                              f"Actual: {group_survival_rate:.3f}, "
                              f"Predicted: {predicted_survival_rate:.3f}, "
                              f"Bias: {age_bias[str(age_group)]['bias']:+.3f}")
                
                bias_results['age_bias'] = age_bias
            except Exception as e:
                print(f"    ‚ö†Ô∏è Could not analyze age bias: {e}")
        
        # Event-based bias analysis
        print(f"\nüìà Event-Based Bias Analysis:")
        event_types = ['has_investment_events', 'has_acquisition_events', 'has_ipo_events', 'has_education_events']
        event_bias = {}
        
        for event_type in event_types:
            has_event_mask = np.array([m.get(event_type, False) for m in self.metadata])
            no_event_mask = ~has_event_mask
            
            if has_event_mask.sum() > 10 and no_event_mask.sum() > 10:
                # With events
                with_event_accuracy = (self.predictions[has_event_mask] == self.labels[has_event_mask]).mean()
                with_event_survival = self.labels[has_event_mask].mean()
                with_event_predicted = self.predictions[has_event_mask].mean()
                
                # Without events
                without_event_accuracy = (self.predictions[no_event_mask] == self.labels[no_event_mask]).mean()
                without_event_survival = self.labels[no_event_mask].mean()
                without_event_predicted = self.predictions[no_event_mask].mean()
                
                event_bias[event_type] = {
                    'with_events': {
                        'count': has_event_mask.sum(),
                        'accuracy': with_event_accuracy,
                        'actual_survival': with_event_survival,
                        'predicted_survival': with_event_predicted,
                        'bias': with_event_predicted - with_event_survival
                    },
                    'without_events': {
                        'count': no_event_mask.sum(),
                        'accuracy': without_event_accuracy,
                        'actual_survival': without_event_survival,
                        'predicted_survival': without_event_predicted,
                        'bias': without_event_predicted - without_event_survival
                    }
                }
                
                print(f"    {event_type.replace('has_', '').replace('_events', '')}:")
                print(f"      With events: {has_event_mask.sum()} samples, "
                      f"Acc: {with_event_accuracy:.3f}, Bias: {event_bias[event_type]['with_events']['bias']:+.3f}")
                print(f"      Without events: {no_event_mask.sum()} samples, "
                      f"Acc: {without_event_accuracy:.3f}, Bias: {event_bias[event_type]['without_events']['bias']:+.3f}")
        
        bias_results['event_bias'] = event_bias
        
        # Summary of bias findings
        print(f"\nüìä Bias Summary:")
        print(f"  - Analyzed bias across geographic, industry, age, and event dimensions")
        print(f"  - Bias score = predicted_rate - actual_rate")
        print(f"  - Positive bias = model over-predicts survival")
        print(f"  - Negative bias = model under-predicts survival")
        
        self.bias_analysis = bias_results
        return bias_results
    
    def analyze_data_contribution(self):
        """Analyze contribution of different data types to predictions"""
        print("\nüìä DATA CONTRIBUTION ANALYSIS")
        print("-" * 50)
        
        # Event contribution analysis
        print(f"üìà Event Type Contribution Analysis:")
        
        event_contributions = {}
        
        # Investment events
        investment_mask = np.array([m.get('has_investment_events', False) for m in self.metadata])
        if investment_mask.sum() > 0:
            inv_survival_rate = self.labels[investment_mask].mean()
            inv_predicted_rate = self.predictions[investment_mask].mean()
            inv_accuracy = (self.predictions[investment_mask] == self.labels[investment_mask]).mean()
            
            event_contributions['investment'] = {
                'count': investment_mask.sum(),
                'percentage': investment_mask.mean() * 100,
                'survival_rate': inv_survival_rate,
                'predicted_rate': inv_predicted_rate,
                'accuracy': inv_accuracy
            }
            
            print(f"  Investment Events: {investment_mask.sum():,} companies ({investment_mask.mean()*100:.1f}%)")
            print(f"    Actual survival rate: {inv_survival_rate:.3f}")
            print(f"    Predicted survival rate: {inv_predicted_rate:.3f}")
            print(f"    Accuracy: {inv_accuracy:.3f}")
        
        # IPO events
        ipo_mask = np.array([m.get('has_ipo_events', False) for m in self.metadata])
        if ipo_mask.sum() > 0:
            ipo_survival_rate = self.labels[ipo_mask].mean()
            ipo_predicted_rate = self.predictions[ipo_mask].mean()
            ipo_accuracy = (self.predictions[ipo_mask] == self.labels[ipo_mask]).mean()
            
            event_contributions['ipo'] = {
                'count': ipo_mask.sum(),
                'percentage': ipo_mask.mean() * 100,
                'survival_rate': ipo_survival_rate,
                'predicted_rate': ipo_predicted_rate,
                'accuracy': ipo_accuracy
            }
            
            print(f"  IPO Events: {ipo_mask.sum():,} companies ({ipo_mask.mean()*100:.1f}%)")
            print(f"    Actual survival rate: {ipo_survival_rate:.3f}")
            print(f"    Predicted survival rate: {ipo_predicted_rate:.3f}")
            print(f"    Accuracy: {ipo_accuracy:.3f}")
        
        # Acquisition events
        acq_mask = np.array([m.get('has_acquisition_events', False) for m in self.metadata])
        if acq_mask.sum() > 0:
            acq_survival_rate = self.labels[acq_mask].mean()
            acq_predicted_rate = self.predictions[acq_mask].mean()
            acq_accuracy = (self.predictions[acq_mask] == self.labels[acq_mask]).mean()
            
            event_contributions['acquisition'] = {
                'count': acq_mask.sum(),
                'percentage': acq_mask.mean() * 100,
                'survival_rate': acq_survival_rate,
                'predicted_rate': acq_predicted_rate,
                'accuracy': acq_accuracy
            }
            
            print(f"  Acquisition Events: {acq_mask.sum():,} companies ({acq_mask.mean()*100:.1f}%)")
            print(f"    Actual survival rate: {acq_survival_rate:.3f}")
            print(f"    Predicted survival rate: {acq_predicted_rate:.3f}")
            print(f"    Accuracy: {acq_accuracy:.3f}")
        
        # Sequence length contribution
        print(f"\nüìè Sequence Length Analysis:")
        seq_lengths = [m['sequence_length'] for m in self.metadata]
        
        if len(seq_lengths) > 0:
            # Divide into quartiles
            length_quartiles = np.percentile(seq_lengths, [25, 50, 75])
            
            length_contributions = {}
            
            for i, (lower, upper) in enumerate([(0, length_quartiles[0]), 
                                               (length_quartiles[0], length_quartiles[1]),
                                               (length_quartiles[1], length_quartiles[2]), 
                                               (length_quartiles[2], np.inf)]):
                if upper == np.inf:
                    length_mask = np.array([l >= lower for l in seq_lengths])
                    quartile_name = f"Q4 (‚â•{lower:.0f})"
                else:
                    length_mask = np.array([lower <= l < upper for l in seq_lengths])
                    quartile_name = f"Q{i+1} ({lower:.0f}-{upper:.0f})"
                
                if length_mask.sum() > 0:
                    quartile_survival = self.labels[length_mask].mean()
                    quartile_predicted = self.predictions[length_mask].mean()
                    quartile_accuracy = (self.predictions[length_mask] == self.labels[length_mask]).mean()
                    
                    length_contributions[f"quartile_{i+1}"] = {
                        'name': quartile_name,
                        'count': length_mask.sum(),
                        'avg_length': np.mean(np.array(seq_lengths)[length_mask]),
                        'survival_rate': quartile_survival,
                        'predicted_rate': quartile_predicted,
                        'accuracy': quartile_accuracy
                    }
                    
                    print(f"  {quartile_name}: {length_mask.sum():,} companies")
                    print(f"    Avg length: {np.mean(np.array(seq_lengths)[length_mask]):.1f}")
                    print(f"    Survival rate: {quartile_survival:.3f}")
                    print(f"    Predicted rate: {quartile_predicted:.3f}")
                    print(f"    Accuracy: {quartile_accuracy:.3f}")
        
        # Token diversity analysis
        print(f"\nüé≤ Token Diversity Analysis:")
        diversities = [m.get('token_diversity', 0) for m in self.metadata]
        
        if len(diversities) > 0 and max(diversities) > 0:
            # Divide into high/low diversity
            diversity_median = np.median([d for d in diversities if d > 0])
            
            high_diversity_mask = np.array([d >= diversity_median for d in diversities])
            low_diversity_mask = np.array([0 < d < diversity_median for d in diversities])
            
            if high_diversity_mask.sum() > 0 and low_diversity_mask.sum() > 0:
                # High diversity
                high_div_survival = self.labels[high_diversity_mask].mean()
                high_div_predicted = self.predictions[high_diversity_mask].mean()
                high_div_accuracy = (self.predictions[high_diversity_mask] == self.labels[high_diversity_mask]).mean()
                
                # Low diversity
                low_div_survival = self.labels[low_diversity_mask].mean()
                low_div_predicted = self.predictions[low_diversity_mask].mean()
                low_div_accuracy = (self.predictions[low_diversity_mask] == self.labels[low_diversity_mask]).mean()
                
                print(f"  High Diversity (‚â•{diversity_median:.3f}): {high_diversity_mask.sum():,} companies")
                print(f"    Survival rate: {high_div_survival:.3f}")
                print(f"    Predicted rate: {high_div_predicted:.3f}")
                print(f"    Accuracy: {high_div_accuracy:.3f}")
                
                print(f"  Low Diversity (<{diversity_median:.3f}): {low_diversity_mask.sum():,} companies")
                print(f"    Survival rate: {low_div_survival:.3f}")
                print(f"    Predicted rate: {low_div_predicted:.3f}")
                print(f"    Accuracy: {low_div_accuracy:.3f}")
        
        self.data_contribution_analysis = {
            'event_contributions': event_contributions,
            'length_contributions': length_contributions if 'length_contributions' in locals() else {},
            'diversity_analysis': {
                'high_diversity': {
                    'count': high_diversity_mask.sum() if 'high_diversity_mask' in locals() else 0,
                    'survival_rate': high_div_survival if 'high_div_survival' in locals() else 0,
                    'accuracy': high_div_accuracy if 'high_div_accuracy' in locals() else 0
                },
                'low_diversity': {
                    'count': low_diversity_mask.sum() if 'low_diversity_mask' in locals() else 0,
                    'survival_rate': low_div_survival if 'low_div_survival' in locals() else 0,
                    'accuracy': low_div_accuracy if 'low_div_accuracy' in locals() else 0
                }
            }
        }
        
        return self.data_contribution_analysis
    
    def generate_comprehensive_report(self):
        """Generate a comprehensive interpretability report"""
        print("\nüìã GENERATING COMPREHENSIVE REPORT")
        print("=" * 60)
        
        report_path = os.path.join(self.output_dir, "interpretability_report.txt")
        
        with open(report_path, 'w') as f:
            f.write("STARTUP2VEC INTERPRETABILITY ANALYSIS REPORT\n")
            f.write("=" * 60 + "\n\n")
            
            # Basic information
            f.write("BASIC INFORMATION\n")
            f.write("-" * 30 + "\n")
            f.write(f"Total samples analyzed: {len(self.predictions):,}\n")
            f.write(f"Model checkpoint: {self.checkpoint_path}\n")
            f.write(f"Analysis timestamp: {time.strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            # Performance metrics
            if self.performance_metrics:
                f.write("PERFORMANCE METRICS\n")
                f.write("-" * 30 + "\n")
                f.write(f"Accuracy: {self.performance_metrics['accuracy']:.4f}\n")
                f.write(f"Balanced Accuracy: {self.performance_metrics['balanced_accuracy']:.4f}\n")
                f.write(f"F1 Score: {self.performance_metrics['f1_score']:.4f}\n")
                f.write(f"Precision: {self.performance_metrics['precision']:.4f}\n")
                f.write(f"Recall: {self.performance_metrics['recall']:.4f}\n")
                f.write(f"Matthews Correlation Coefficient: {self.performance_metrics['mcc']:.4f}\n")
                f.write(f"AUC-ROC: {self.performance_metrics['auc_roc']:.4f}\n")
                f.write(f"Average Precision: {self.performance_metrics['average_precision']:.4f}\n\n")
            
            # Token analysis
            if self.token_frequencies:
                f.write("TOKEN ANALYSIS\n")
                f.write("-" * 30 + "\n")
                f.write(f"Total unique tokens: {len(self.token_frequencies['token_counts']):,}\n")
                f.write(f"High-frequency tokens: {len(self.token_frequencies['frequent_tokens']):,}\n")
                f.write(f"Rare tokens: {len(self.token_frequencies['rare_tokens']):,}\n")
                f.write(f"Average tokens per sequence: {self.token_frequencies['avg_tokens_per_sequence']:.1f}\n\n")
            
            # Startup characteristics
            if self.startup_characteristics:
                f.write("STARTUP CHARACTERISTICS\n")
                f.write("-" * 30 + "\n")
                
                f.write("Top Countries:\n")
                for country, count in self.startup_characteristics['countries'].most_common(10):
                    f.write(f"  {country}: {count:,}\n")
                
                f.write("\nTop Industries:\n")
                for industry, count in self.startup_characteristics['industries'].most_common(10):
                    f.write(f"  {industry}: {count:,}\n")
                
                f.write(f"\nEvent Statistics:\n")
                events = self.startup_characteristics['event_stats']
                total_samples = len(self.metadata)
                for event_type, count in events.items():
                    percentage = count / total_samples * 100
                    f.write(f"  {event_type}: {count:,} ({percentage:.1f}%)\n")
                
                f.write("\n")
            
            # Bias analysis
            if self.bias_analysis:
                f.write("BIAS ANALYSIS SUMMARY\n")
                f.write("-" * 30 + "\n")
                
                if 'country_bias' in self.bias_analysis:
                    f.write("Geographic Bias (top countries):\n")
                    for country, bias_data in list(self.bias_analysis['country_bias'].items())[:5]:
                        f.write(f"  {country}: Bias = {bias_data['bias']:+.3f}, "
                               f"Accuracy = {bias_data['accuracy']:.3f}\n")
                
                if 'industry_bias' in self.bias_analysis:
                    f.write("\nIndustry Bias (top industries):\n")
                    for industry, bias_data in list(self.bias_analysis['industry_bias'].items())[:5]:
                        f.write(f"  {industry}: Bias = {bias_data['bias']:+.3f}, "
                               f"Accuracy = {bias_data['accuracy']:.3f}\n")
                
                f.write("\n")
            
            # Token importance
            if self.token_importance_scores:
                f.write("TOP IMPORTANT TOKENS\n")
                f.write("-" * 30 + "\n")
                
                for token_id, scores in self.token_importance_scores['sorted_tokens'][:20]:
                    token_name = self.idx_to_vocab.get(token_id, f"Token_{token_id}")
                    f.write(f"  {token_name}: Importance = {scores['importance_score']:.4f}, "
                           f"Survival Rate = {scores['survival_rate']:.3f}\n")
                
                f.write("\n")
            
            f.write("END OF REPORT\n")
        
        print(f"‚úÖ Comprehensive report saved to: {report_path}")
        
        # Save analysis data
        analysis_data = {
            'performance_metrics': self.performance_metrics,
            'startup_characteristics': self.startup_characteristics,
            'token_frequencies': self.token_frequencies,
            'token_importance_scores': self.token_importance_scores,
            'embedding_analysis': self.embedding_analysis,
            'bias_analysis': self.bias_analysis,
            'prediction_analysis': self.prediction_analysis,
            'data_contribution_analysis': getattr(self, 'data_contribution_analysis', None)
        }
        
        pickle_path = os.path.join(self.output_dir, "analysis_data.pkl")
        with open(pickle_path, 'wb') as f:
            pickle.dump(analysis_data, f)
        
        print(f"‚úÖ Analysis data saved to: {pickle_path}")
        
        return report_path
    
    def run_complete_analysis(self, target_batches=500, balanced_sampling=False):
        """Run COMPLETE interpretability analysis with ALL methods"""
        print("üöÄ COMPLETE FULL STARTUP2VEC INTERPRETABILITY ANALYSIS")
        print("=" * 90)
        print("Complete analysis with FIXED balanced sampling, CUDA memory management, and ALL analyses")
        print()
        
        # Load model and data
        if not self.load_model_and_data():
            return False
        
        # Extract data with all fixes
        if not self.extract_data_with_characteristics(target_batches, balanced_sampling):
            return False
        
        # Run ALL analysis methods
        print("\n" + "="*60)
        print("RUNNING ALL INTERPRETABILITY ANALYSES")
        print("="*60)
        
        try:
            # Token importance analysis
            self.analyze_token_importance()
            
            # Embedding analysis  
            self.analyze_embeddings()
            
            # Prediction pattern analysis
            self.analyze_prediction_patterns()
            
            # Algorithmic bias analysis
            self.analyze_algorithmic_bias()
            
            # Data contribution analysis
            self.analyze_data_contribution()
            
            # Generate comprehensive report
            report_path = self.generate_comprehensive_report()
            
        except Exception as e:
            print(f"‚ö†Ô∏è Error during analysis: {e}")
            print("Continuing with basic analysis...")
        
        print(f"\nüéâ COMPLETE FULL ANALYSIS FINISHED!")
        print(f"üìä Analyzed {len(self.predictions):,} startup samples")
        print(f"üìÅ Results saved to: {self.output_dir}/")
        
        # Verification of fixes
        if balanced_sampling and len(self.predictions) > 0:
            unique_labels, counts = np.unique(self.labels, return_counts=True)
            print(f"‚úÖ FIXED balanced sampling verification:")
            print(f"   Class distribution: {dict(zip(unique_labels, counts))}")
            if len(counts) == 2 and abs(counts[0] - counts[1]) <= 1:
                print(f"   ‚úÖ Perfect balance achieved!")
            else:
                print(f"   ‚ö†Ô∏è Some imbalance remaining")
        
        return True

def main():
    """COMPLETE FULL main function with ALL analyses"""
    checkpoint_path = "./survival_checkpoints/fixed-survival-prediction/best-epoch=01-val/auc=0.6709.ckpt"
    pretrained_path = "./startup2vec_startup2vec-full-1gpu-512d_final.pt"
    
    # Check GPU status
    print("üîß COMPLETE FULL STARTUP2VEC INTERPRETABILITY ANALYSIS")
    print("="*75)
    
    if torch.cuda.is_available():
        gpu_count = torch.cuda.device_count()
        current_device = torch.cuda.current_device()
        cuda_visible = os.environ.get('CUDA_VISIBLE_DEVICES', 'Not set')
        
        print(f"üöÄ CUDA Available: {gpu_count} GPU(s)")
        print(f"üì± Current Device: GPU {current_device}")
        print(f"üéØ CUDA_VISIBLE_DEVICES: {cuda_visible}")
        
        if cuda_visible == 'Not set':
            print("‚ö†Ô∏è  Consider setting CUDA_VISIBLE_DEVICES for specific GPU")
    else:
        print("‚ùå CUDA not available - will use CPU")
    
    print()
    print("üéØ COMPLETE FULL FEATURES INCLUDED:")
    print("‚úÖ FIXED balanced sampling bug (truly different success/failure samples)")
    print("‚úÖ FIXED CUDA memory management (graceful fallback to CPU)")
    print("‚úÖ Reduced batch size (16 instead of 32)")
    print("‚úÖ Memory clearing and error handling")
    print("‚úÖ ALL interpretability analyses:")
    print("   ‚Ä¢ Token importance analysis")
    print("   ‚Ä¢ Embedding analysis with PCA and clustering")
    print("   ‚Ä¢ Prediction pattern and confidence analysis")
    print("   ‚Ä¢ Algorithmic bias analysis (geographic, industry, age, events)")
    print("   ‚Ä¢ Data contribution analysis")
    print("   ‚Ä¢ Comprehensive report generation")
    print()
    
    analyzer = CompleteFullStartupInterpretabilityAnalyzer(
        checkpoint_path=checkpoint_path,
        pretrained_path=pretrained_path,
        output_dir="startup_interpretability_complete_full"
    )
    
    # Get user preferences
    print("üéõÔ∏è ANALYSIS OPTIONS:")
    print("1. Standard analysis (original data distribution)")
    print("2. FIXED balanced analysis (truly equal success/failure samples)")
    
    choice = input("Choose analysis type (1 or 2): ").strip()
    balanced_sampling = choice == "2"
    
    if balanced_sampling:
        print("üéØ Using FIXED balanced sampling")
    else:
        print("üìä Using original data distribution")
    
    batch_choice = input("Enter number of batches (0 for ALL data, 500+ recommended): ").strip()
    try:
        target_batches = int(batch_choice)
    except ValueError:
        target_batches = 500
    
    if target_batches == 0:
        print("üî• Running FULL SAMPLE analysis!")
        print("‚ö†Ô∏è This will process all available data")
    else:
        print(f"üöÄ Running analysis with {target_batches} batches...")
    
    # Start analysis with timing
    start_time = time.time()
    success = analyzer.run_complete_analysis(
        target_batches=target_batches,
        balanced_sampling=balanced_sampling
    )
    end_time = time.time()
    
    if success:
        print(f"\nüéâ SUCCESS! Complete full analysis completed in {end_time-start_time:.1f} seconds")
        print(f"üìä Successfully processed {len(analyzer.predictions):,} samples")
        
        print("\nüîß ALL FEATURES APPLIED:")
        print("  ‚úÖ Balanced sampling uses truly different samples")
        print("  ‚úÖ CUDA memory managed with CPU fallback")
        print("  ‚úÖ No more memory crashes")
        print("  ‚úÖ Robust error handling")
        print("  ‚úÖ ALL interpretability analyses completed")
        
        print("\nüìÅ OUTPUT:")
        print(f"  Directory: startup_interpretability_complete_full/")
        print(f"  Comprehensive report: interpretability_report.txt")
        print(f"  Analysis data: analysis_data.pkl")
        
        print("\nüí° NEXT STEPS:")
        print("  1. Check interpretability_report.txt for comprehensive findings")
        print("  2. Use analysis_data.pkl for further analysis in Jupyter")
        print("  3. Compare balanced vs unbalanced results")
        print("  4. Use findings for thesis bias analysis")
        
        return 0
    else:
        print(f"\n‚ùå Analysis failed after {end_time-start_time:.1f} seconds")
        print("üí° TROUBLESHOOTING:")
        print("  1. Try smaller target_batches")
        print("  2. Force CPU with: CUDA_VISIBLE_DEVICES=''")
        print("  3. Check available memory")
        return 1

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
